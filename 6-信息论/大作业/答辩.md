## 非参数估计方法

### 数据分箱

数据分箱是一种将连续的数据转换成离散的、有限个“箱子”（bins）或区间（intervals）的方法。它的核心思想是，通过统计数据点在预先划分好的各个区域（箱子）内的频率，来近似表示原始数据的概率分布。

####  工作原理

该方法在理论上非常直观，主要分为以下几个步骤 ：

1. **划分特征空间（Partitioning）**：首先，将数据所在的整个特征空间（即所有可能值的范围）分割成一系列互不重叠的区域，这些区域就是“箱子”。
   - **一维情况**：如果数据只有一个维度（例如，学生的身高），就是将身高范围（如150cm到200cm）切分成多个小区间（如150-155cm, 155-160cm, ...）。
   - **高维情况**：如果数据有多个维度（例如，深度学习模型输出的数百维特征向量），就需要将这个高维空间切分成一个个“超立方体”网格。
2. **统计频数（Counting）**：遍历所有的样本数据点，计算每个箱子内落入了多少个数据点。
3. **估计概率密度（Estimating Probability）**：用落在某个箱子内的数据点数量除以总的样本数量，就可以得到该箱子所代表区域的概率估计。所有箱子的概率估计组合在一起，就形成了一个直方图，这个直方图就是对原始数据概率密度函数的一个离散近似。
4. **计算互信息（Calculating Mutual Information）**：一旦获得了近似的概率密度函数，就可以将其代入信息论的香农公式，来计算熵（Entropy）和互信息（Mutual Information）等指标 。

#### 主要优点

- **直观易懂**：该方法在理论上非常直观，容易理解和实现 。

#### 致命缺陷：“维度灾难”

尽管数据分箱方法很直观，但报告明确指出，它在实践中面临着严峻的 

**“维度灾难”（Curse of Dimensionality）** 问题，尤其是在处理深度学习产生的高维数据时 

“维度灾难”对数据分箱的影响体现在：

- **所需样本量指数级增长**：随着数据维度（即特征数量）的增加，要保持对概率密度的准确估计，所需的样本数量会呈指数级增长 。
- **“箱子”数量爆炸**：假设我们为每个维度划分10个箱子。
  - 对于1维数据，需要10个箱子。
  - 对于2维数据，需要 10×10=100 个箱子。
  - 对于深度学习中常见的数百乃至数千维的特征向量，所需的箱子数量将是一个天文数字 (10100 或更多)。
- **数据稀疏性**：在有限的样本下，高维空间中的绝大多数“箱子”都会是空的，或者只包含极少数几个数据点。基于这样稀疏的数据得到的概率估计是极不可靠的。

### 核密度估计

核密度估计（KDE）是一种用于估计随机变量概率密度函数的非参数方法。与数据分箱（直方图法）将数据放入离散的“箱子”中不同，KDE通过在每个数据点上放置一个平滑的“核函数”（Kernel），并将这些核函数叠加起来，从而生成一条平滑、连续的密度曲线。

#### 工作原理

KDE的核心思想是，数据集中的每个数据点都对其周围区域的概率密度有贡献。一个数据点所在位置的密度应该更高，离它越远的地方，它所贡献的密度就越小。

其工作步骤如下：

1. **选择核函数 (Kernel Function)**：核函数是一个对称的、积分为1的函数，它决定了单个数据点如何贡献其周围的密度。最常用的核函数是高斯函数（即正态分布曲线），其形状像一个平滑的“钟形”。
2. **在每个数据点上放置核函数**：遍历数据集中的每一个数据点，以该数据点为中心放置一个核函数。这样，每个数据点都生成了一个小小的“密度山丘”。
3. **设定带宽 (Bandwidth, h)**：带宽是一个至关重要的平滑参数，它控制了每个核函数的“胖瘦”（即影响范围）。
   - **小带宽 (small h)**：核函数变得非常尖瘦。最终的密度曲线会非常“抖动”，能捕捉到数据的细微结构，但也可能过度拟合，产生很多噪声。
   - **大带宽 (large h)**：核函数变得非常扁平。最终的密度曲线会非常平滑，能反映数据的大趋势，但也可能过度平滑，掩盖掉重要的局部特征。
4. **叠加与平均**：将所有数据点上放置的核函数进行叠加，然后求平均，就得到了整个数据集的最终概率密度估计函数。在任意一点 `x` 的密度值，就是所有数据点上的核函数在该点 `x` 处函数值的总和的平均。

#### 在报告中的作用与局限

- **作用**：在报告的论述中，KDE和数据分箱一样，其目的是为了先估计出高维数据（如模型特征向量）的概率密度函数，然后再将这个函数代入香农公式，用以计算互信息 。
- **致命缺陷：“维度灾难”**：报告同样指出，KDE虽然比数据分箱更优越，但在实践中也面临着严峻的“维度灾难”问题 。
  - **空间稀疏性**：随着维度的增加，数据点之间的距离会急剧增大，整个数据空间变得极其稀疏。
  - **估计失效**：在进行核密度估计时，对于空间中的任意一点，都很难在其附近找到足够多的数据点来提供有意义的密度贡献。几乎所有的数据点都离它很“远”，导致该点的密度估计值趋近于零。
  - **样本需求**：为了在高维空间中获得可靠的密度估计，所需的样本数量会呈指数级增长 。

## 基于神经网络的变分下界估计方法

### 互信息神经估计器(MINE)

互信息的直接计算非常困难，因为它涉及到对数概率密度的复杂积分。MINE 的核心思想是**不直接计算互信息本身，而是计算它的一个可微的、可优化的“变分下界”（Variational Lower Bound）**。通过最大化这个下界，来间接最大化互信息。

这一过程基于 Donsker-Varadhan 提出的 KL 散度表示法，其工作原理可以概括为：

1. **引入辅助神经网络**：MINE 引入一个辅助的神经网络，在报告中被称为“判别器网络”（discriminator network）。这个网络的作用是区分两种样本：

   - **正样本**：从两个变量的**联合分布** P(X,Y) 中抽取的样本对 (x,y)。这些是真实的、配对的数据。
   - **负样本**：从两个变量的**边缘分布的乘积** P(X)P(Y) 中抽取的样本对 (x,y′)。这些是“假的”、不配对的数据（例如，一张猫的图片配上描述狗的文本）。

2. **构建下界**：该判别器网络被训练来给正样本打高分，给负样本打低分。MINE 证明了，通过巧妙地设计目标函数（即互信息的下界），网络的训练过程等价于在优化互信息。这个下界公式大致如下：

   ![image-20250702150936295](C:/Users/ASUS/AppData/Roaming/Typora/typora-user-images/image-20250702150936295.png)

3. **优化过程**：通过梯度上升等方法，训练神经网络 T 来最大化这个下界 I^(X,Y)。当这个下界被最大化时，它就成了对真实互信息的一个良好估计。

这个框架的巧妙之处在于，它将一个复杂的、难以直接计算的互信息问题，

**转化成了一个更易于处理的、可微的下界优化问题** ，非常适合用深度学习的框架（如梯度下降）来求解。

### 优点

- **克服维度灾难**：它不需要估计概率密度函数，因此能有效处理高维数据。
- **适用性广**：可用于连续或离散数据，并且能整合到任何基于梯度优化的机器学习模型中。
- **应用成功**：MINE 及其变体在许多任务中取得了显著成功 。

### 报告中指出的局限性

尽管 MINE 非常成功，但报告也明确指出了它引入的新问题和复杂性 ：

- **依赖辅助网络**：框架的性能高度依赖于辅助判别器的设计与训练，这增加了模型整体的复杂度 。
- **训练不稳定**：它可能引入对抗性训练过程中的不稳定性 。
- **下界不紧 (non-tight)**：优化的只是一个下界，如果这个下界与真实的互信息值差距很大（即“不紧”），那么优化这个下界也无法保证总能精确地导向互信息的最大化 。

## 图二：长序列分层剪枝的t-SNE可视化

基于矩阵熵的分层剪枝方案，能够成功地将一个包含256个Token的大型、冗余的序列，智能地压缩成一个仅包含21个Token的小型、高效的序列。这个新序列不仅去除了冗余，还最大程度地保留了原始图像的多样性和核心语义信息。

### 图中元素的含义

- **彩色数据点 (Colored Dots)**：
  - 这些点代表了原始的**256个视觉Token**。
  - 不同的颜色代表不同的**语义簇（Semantic Clusters）**。这些簇是通过K-Means算法计算得出的，该算法将语义上相近的Token自动聚合在一起 。例如，所有红色的点代表一个簇，所有绿色的点代表另一个簇。
- **黑色的“X”标记 (Black 'X' Markers)**：
  - 这些标记代表**“Kept Tokens”**，即经过剪枝算法筛选后，最终被**保留下来的Token**。
  - 根据图例，本次剪枝操作后共保留了**21个**Token 。

### 该图揭示的核心思想

1. **聚类效果显著**：从图中可以看出，相同颜色的数据点都紧密地聚集在一起，形成清晰的团块。这表明K-Means算法成功地识别并划分出了多个具有不同语义内涵的Token簇。
2. **剪枝策略的智能性**：被保留下来的21个黑色“X”标记，并非集中在某一个或两个簇内，而是**广泛地分布在不同的颜色簇之中**。这正是该算法的核心优势所在：
   - 它不是简单地保留最“强”的一批Token，因为这些Token可能都属于同一个语义簇（例如，都描述天空的细节），从而导致信息冗余。
   - 相反，该算法先评估**哪个“簇”更重要**，然后从这些最重要的簇中，各自挑选出**最具代表性的Token**予以保留 。
   - 这样做可以确保最终保留下来的21个Token，虽然数量少，但其语义覆盖面广，分别代表了原始图像中不同方面（例如，天空、建筑、人物、地面等）的核心信息，构成了一组信息密度高且多样化的代表。

## 算法一

#### **步骤一：Token聚类 (第1-2行)**

- **第2行**: `KMeans(T, M)` 。算法首先调用K-Means聚类方法，将输入的N个原始Token（T）划分成M个语义上互不重叠的簇（{C1,...,CM}） 。在这一步，语义相似的Token会被自动聚合在一起。

#### **步骤二：生成元序列 (第3-8行)**

这一步的目的是为每个簇创建一个代表，从而将长序列压缩成一个短的“元序列”，以便进行高效的重要性评估。

- **第5-8行**: 算法遍历第一步中产生的M个簇 。
- **第6行**: `c_j <- ...` 。对于每个簇 Cj，算法计算其**质心 (centroid)**，即该簇内所有Token向量的平均值 。这个质心向量可以被看作是该簇核心语义的代表 。
- **第7行**: `T_cluster <- ...` 。所有M个质心被收集起来，构成一个新的、长度为M的短序列，即**“元序列” Tcluster** 。

#### **步骤三：评估每个簇的重要性 (第9-10行)**

这是算法的核心决策步骤。

- **第10行**: `ComputeClusterImportance(T_cluster)` 。算法调用一个函数来计算每个簇的重要性。如注释`(嵌套矩阵熵评估)`所示 ，这个函数内部使用了计算成本高昂的矩阵熵方法。但关键在于，该方法此时作用于长度仅为M的元序列，而非长度为N的原始序列，从而使得计算变得可行。该函数会为每个簇的质心计算一个重要性得分(Sj)，得分越高，代表该簇包含的信息越重要、越不可替代 。

#### **步骤四：执行自适应分层剪枝 (第11-20行)**

在获得所有簇的重要性得分后，算法开始进行最终的筛选和剪枝。

- **第12行**: `TopK_Indices(...)` 。根据上一步得到的得分，算法选出得分最高的 **kc 个簇**的索引 。
- **第14-18行**: 算法遍历这些被选中的“核心簇” 。
- **第16行**: `FindNearestTokens(...)` 。对于每一个核心簇，算法会在该簇内部找到**离其质心最近的 tpc 个原始Token** 。这些Token被认为是该簇内最具代表性的成员。
- **第17行**: `T_pruned <- ...` 。这些被选出的代表性Token被收集到最终的剪枝后序列 Tpruned 中 。
- **第19行**: `Sort(...) (optional)` 。这是一个可选步骤，可以将最终保留的Token按照它们在原始序列中的位置进行排序，以维持序列的原始顺序 。
- **第20行**: `return T_pruned` 。算法返回最终的、经过剪枝的、信息密度更高的Token序列 。

### K-Means（使用`sklearn.cluster.KMeans`可以非常方便地实现）

K-Means算法的核心目标是将N个数据点划分到K个簇中，使得每个数据点都属于离其最近的簇的中心（即“质心”），从而最小化簇内数据点到其质心的距离平方和。简而言之，它试图让簇内的点尽可能相似（靠得近），而簇与簇之间的点尽可能不同（离得远）。

K-Means是一个迭代算法，其工作流程通常包括以下四个步骤：

1. **步骤一：初始化 (Initialization)**
   - 首先，需要预先指定簇的数量，即参数“K”。
   - 然后，从数据集中随机选择K个数据点作为初始的簇质心（Centroids）。
2. **步骤二：分配 (Assignment)**
   - 遍历数据集中的每一个数据点。
   - 计算该点到所有K个质心的距离（通常使用欧氏距离）。
   - 将该数据点分配给距离其最近的那个质心所代表的簇。
3. **步骤三：更新 (Update)**
   - 在所有数据点都被分配到簇之后，重新计算每个簇的质心。
   - 新的质心是该簇内所有数据点的平均值。在您提供的报告中，这一步对应于计算每个簇的质心向量 。
4. **步骤四：迭代 (Iteration)**
   - 重复执行**步骤二（分配）\**和\**步骤三（更新）**。
   - 这个迭代过程会持续进行，直到满足某个停止条件。

算法的迭代过程会在以下情况之一发生时停止：

- **质心不再变化**：在一次迭代中，所有簇的质心位置都保持不变或变化极小。
- **分配不再变化**：数据点的簇归属不再发生改变。
- **达到最大迭代次数**：为防止无限循环，通常会设置一个最大的迭代次数。

### Attention Rollout

- **初始化 (l=l1)**: 合并过程从第 l1 层开始，该层的合并后矩阵熵 H~l1 直接等于其原始计算出的矩阵熵 Hl1 。

- **递归步骤 (l1<l≤l2)**: 对于后续的每一层 l，其合并后的矩阵熵 H~l 是由当前层的原始矩阵熵 Hl（加上一个单位矩阵I）与上一层合并后的结果 H~l−1 相乘得到的 。这可以理解为将当前层的信息“叠加”到之前所有层累积的信息之上。

### 指标

### 1. BLEU-4 (Bilingual Evaluation Understudy)

- **核心思想**：衡量“生成文本”和“参考文本”之间n-gram（n元语法）的重合度。它是一种基于**精确率 (Precision)** 的方法。
- **工作原理**：
  - 它会计算1-gram, 2-gram, 3-gram, 和 4-gram（即连续的1、2、3、4个词的组合）在生成文本和参考文本中共同出现的比例。
  - **BLEU-4** 表示它会综合考虑从1-gram到4-gram的匹配情况，并计算一个加权几何平均值。
  - 为了惩罚那些虽然精确率高但句子过短的生成结果（例如，只生成一个“the”），BLEU引入了“简短惩罚因子”（Brevity Penalty）。
- **优点**：计算速度快，与人类判断有一定的相关性。
- **缺点**：不考虑同义词，对句子结构和语法不敏感，有时与人类的直观感受有出入。

### 2. METEOR (Metric for Evaluation of Translation with Explicit ORdering)

- **核心思想**：旨在改进BLEU的缺点，它在衡量匹配度时同时考虑了**精确率和召回率 (Recall)**。
- **工作原理**：
  - 它首先在生成文本和参考文本之间寻找最佳的词对齐。
  - 与BLEU不同，METEOR能够识别**同义词**和**词干相同**的词（例如，“run” 和 “running”），而不仅仅是完全相同的词。
  - 它使用精确率和召回率的调和平均数（Harmonic Mean）来计算最终得分，对词序的流畅性也有一定的惩罚。
- **优点**：比BLEU更考虑语义，与人类判断的相关性更高。

### 3. ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation)

- **核心思想**：ROUGE系列指标主要用于评估自动文摘，它更侧重于**召回率**，即参考文本中的重要信息有多少被生成文本覆盖了。
- **工作原理**：
  - **ROUGE-L** 中的 “L” 代表**最长公共子序列 (Longest Common Subsequence, LCS)**。
  - 它会查找生成文本和参考文本之间最长的共现词语序列，即使这些词在原句中不是连续的。例如，“A B C D” 和 “A X B C Y D” 的LCS就是 “A B C D”。
  - LCS越长，说明生成文本捕捉到了参考文本越多的核心内容。
- **优点**：能很好地反映句子级别结构上的相似性。

### 4. CIDEr (Consensus-based Image Description Evaluation)

- **核心思想**：专门为图像描述任务设计，它认为一个好的描述应该包含被大多数人（共识）认可的、有信息量的表达 。
- **工作原理**：
  - 它将每个句子看作是由n-gram组成的“文档”。
  - 它使用**TF-IDF (词频-逆文档频率)** 的思想来给每个n-gram加权。一个n-gram如果在一张图片的多个参考描述中频繁出现（TF高），但在整个数据集的其他图片描述中很少出现（IDF高），那么它就被认为更能描述这张图片的独特性，权重就更高。
  - 最终通过计算生成描述和参考描述之间加权后的余弦相似度来得到分数。
- **优点**：与人类对图像描述质量的判断高度相关，被认为是图像描述领域最重要的评价指标之一。

### 5. SPICE (Semantic Propositional Image Caption Evaluation)

- **核心思想**：完全脱离了n-gram匹配，专注于评估描述在**语义层面**是否准确 。
- **工作原理**：
  - 它使用场景图（Scene Graph）来分析句子。它会将生成描述和每个参考描述都解析成一个包含物体、属性和它们之间关系的图结构。
  - 例如，对于“一个穿着红色衬衫的男人在踢球”这句话，SPICE会解析出“男人”、“衬衫”、“球”等物体，以及“红色”这个属性和“穿着”、“踢”等关系。
  - 它通过比较生成描述的场景图和参考描述的场景图的重合度来计算分数。
- **优点**：能非常准确地判断描述的语义内容是否正确，即使措辞完全不同。

### 图四

- **横轴 (X-axis)**: 代表通过K-Means算法对原始Token进行聚类后得到的32个独立的**语义簇**，并按重要性得分从高到低进行了排序 。

- **纵轴 (Y-axis)**: 代表**“簇重要性得分 (熵减量)”** ，即"**当该簇的质心从元序列中被移除后，整个元序列信息总量（即矩阵熵）的减少量** "。这个数值是本报告提出的核心度量标准。

#### 图中信息的解读

- **得分高的簇 (左侧深色柱)**: 像Cluster 27, 28, 23等得分远高于零的簇，是信息量最大、最重要的簇。得分高意味着如果移除这些簇，整个序列的信息总量将**显著下降**。这表明它们包含了独特且不可替代的语义信息 。
- **得分低的簇 (中间及右侧浅色柱)**: 像Cluster 5, 22, 0等得分接近零的簇，其包含的信息是**冗余的**。移除它们对整个序列的信息总量影响甚微 。
- **得分为负的簇 (右侧黄色柱)**: 像Cluster 13, 10, 12, 16等得分甚至为负数的簇，表明这些簇可能是噪声或者与其他簇的信息高度相关，移除它们甚至可能对提升剩余信息集合的“纯度”有微弱的正面作用。它们是**最不重要**的簇。

### 图五

### 左图：剪枝前 (Before Pruning)

- **矩阵尺寸**：这是一个 **256x256** 的大型矩阵，代表了原始输入的256个视觉Token两两之间的相似度关系 。矩阵中每个点 (i,j) 的颜色亮度表示第 i 个Token和第 j 个Token的相似度。
- **关键特征**：最引人注目的是，除了主对角线（一个Token与自身的相似度总是最高的）之外，还存在多个**明亮的非对角线“方块”** 。
- **特征解读**：
  - 这些明亮的方块是**信息冗余的直接可视化证据** 。
  - 一个方块区域内的Token在语义上是高度相似的，形成了功能上的重复 。例如，一个方块可能代表了图像中所有描述“天空”的Token，它们彼此之间非常相似。
  - 报告指出，这种明显的冗余结构本身就为进行剪枝提供了充分的理由 。

### 右图：剪枝后 (After Pruning)

- **矩阵尺寸**：矩阵的规模被急剧压缩至 **21x21** 。这意味着算法最终从256个Token中保留了21个。
- **尺寸原因**：这个尺寸是算法**自适应机制**的结果。报告解释说，算法评选出了16个核心语义簇，其中有11个是仅包含单个Token的“独特点”簇，这保证了最终结果是对原始核心信息更高保真度的提炼。
- **关键特征**：
  1. 原先代表冗余信息的亮色方块结构**已完全消失** 。
  2. 取而代之的是一个更加**稀疏、接近准对角化的矩阵** 。除了主对角线非常明亮外，其他区域的颜色都偏暗，表示相似度很低。
- **特征解读**：
  - 这种结构上的根本性变化表明，剪枝操作成功**移除了每个语义簇内部的冗余成员** 。
  - 算法只保留了能够**唯一代表该簇的核心Token** 。
  - 最终得到的21个Token，它们彼此间的语义相似度非常低，构成了一组近似正交的**“语义基向量”** 。这意味着每个被保留下来的Token都携带着独特的信息，最大化了信息密度。

### 总结

总而言之，这张对比图强有力地证明了**Entropy-Pruning**方法的有效性。它不仅仅是简单地丢弃Token，而是通过一种智能的方式，精确地识别并剔除语义上重复的部分，最终提炼出一组小而精、信息量大且互不冗余的核心Token集合，从而为后续的计算大幅减负。

### 复杂度分析

![image-20250703153116825](C:/Users/ASUS/AppData/Roaming/Typora/typora-user-images/image-20250703153116825.png)

![image-20250703153126683](C:/Users/ASUS/AppData/Roaming/Typora/typora-user-images/image-20250703153126683.png)

![image-20250703153138956](C:/Users/ASUS/AppData/Roaming/Typora/typora-user-images/image-20250703153138956.png)

![image-20250703153158621](C:/Users/ASUS/AppData/Roaming/Typora/typora-user-images/image-20250703153158621.png)

